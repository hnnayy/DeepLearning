{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGAj/KM2FT3WLPBaIfHmGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnnayy/DeepLearning/blob/main/week7%20/WMT14/Tensorflow_WMT14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwv8iRSHAAzZ",
        "outputId": "1beca1c4-1d43-40fb-8734-eb2309363e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, GRU, Bidirectional, Embedding, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import io\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "import pandas as pd\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Download necessary nltk resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "MAX_LEN = 50\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the data preprocessing function (assuming data is loaded in de_val, en_val, de_tokenizer, en_tokenizer)\n",
        "def load_and_preprocess_data():\n",
        "    print(\"Memuat dataset...\")\n",
        "    dataset = load_dataset(\"wmt14\", \"de-en\")\n",
        "\n",
        "    # Mengambil 5% data dari train dan validation set\n",
        "    train_dataset = dataset['train'].select(range(int(len(dataset['train']) * 0.05)))\n",
        "    val_dataset = dataset['validation'].select(range(int(len(dataset['validation']) * 0.05)))\n",
        "\n",
        "    # Preprocessing: Tokenisasi dan Padding\n",
        "    def tokenize_and_pad(texts, tokenizer=None, max_len=MAX_LEN):\n",
        "        if tokenizer is None:\n",
        "            tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "            tokenizer.fit_on_texts(texts)\n",
        "        sequences = tokenizer.texts_to_sequences(texts)\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "        return padded_sequences, tokenizer\n",
        "\n",
        "    # Prepare the data\n",
        "    de_sentences = [example['translation']['de'] for example in train_dataset]\n",
        "    en_sentences = [example['translation']['en'] for example in train_dataset]\n",
        "\n",
        "    # Tokenization\n",
        "    de_train, de_tokenizer = tokenize_and_pad(de_sentences, max_len=MAX_LEN)\n",
        "    en_train, en_tokenizer = tokenize_and_pad(en_sentences, max_len=MAX_LEN)\n",
        "\n",
        "    # Start token ID for decoder input\n",
        "    start_token_id = en_tokenizer.word_index.get('<start>', 1)\n",
        "    en_train_shifted = generate_decoder_input(en_train, start_token_id)\n",
        "\n",
        "    # Validation data\n",
        "    de_val_sentences = [example['translation']['de'] for example in val_dataset]\n",
        "    en_val_sentences = [example['translation']['en'] for example in val_dataset]\n",
        "\n",
        "    de_val, _ = tokenize_and_pad(de_val_sentences, tokenizer=de_tokenizer, max_len=MAX_LEN)\n",
        "    en_val, _ = tokenize_and_pad(en_val_sentences, tokenizer=en_tokenizer, max_len=MAX_LEN)\n",
        "    en_val_shifted = generate_decoder_input(en_val, start_token_id)\n",
        "\n",
        "    return de_train, en_train, de_tokenizer, en_tokenizer, en_train_shifted, de_val, en_val, en_val_shifted, train_dataset, val_dataset\n"
      ],
      "metadata": {
        "id": "acgoTyDeB423"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate decoder input by shifting target data (English sentences)\n",
        "def generate_decoder_input(target_data, start_token_id):\n",
        "    decoder_input = np.zeros_like(target_data)  # Create a zero matrix with the same shape as target_data\n",
        "    decoder_input[:, 1:] = target_data[:, :-1]  # Shift the target data to the right\n",
        "    decoder_input[:, 0] = start_token_id  # Set the first token as the start token\n",
        "    return decoder_input"
      ],
      "metadata": {
        "id": "2O9cNxKkCIhU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Build the model\n",
        "def build_model(embedding_dim=256, hidden_units=512, dropout_rate=0.2, cell_type='lstm', bidirectional=False, optimizer='adam', learning_rate=0.001):\n",
        "    encoder_inputs = Input(shape=(None,))\n",
        "    encoder_embedding = Embedding(input_dim=len(de_tokenizer.word_index)+1, output_dim=embedding_dim)(encoder_inputs)\n",
        "\n",
        "    if bidirectional:\n",
        "        if cell_type == 'lstm':\n",
        "            encoder_rnn = Bidirectional(LSTM(hidden_units, return_state=True))\n",
        "            encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_rnn(encoder_embedding)\n",
        "            state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "            state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "            encoder_states = [state_h, state_c]\n",
        "        else:  # GRU\n",
        "            encoder_rnn = Bidirectional(GRU(hidden_units, return_state=True))\n",
        "            encoder_outputs, forward_h, backward_h = encoder_rnn(encoder_embedding)\n",
        "            state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "            encoder_states = [state_h]\n",
        "    else:\n",
        "        if cell_type == 'lstm':\n",
        "            encoder_rnn = LSTM(hidden_units, return_state=True)\n",
        "            encoder_outputs, state_h, state_c = encoder_rnn(encoder_embedding)\n",
        "            encoder_states = [state_h, state_c]\n",
        "        else:  # GRU\n",
        "            encoder_rnn = GRU(hidden_units, return_state=True)\n",
        "            encoder_outputs, state_h = encoder_rnn(encoder_embedding)\n",
        "            encoder_states = [state_h]\n",
        "\n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "    decoder_embedding = Embedding(input_dim=len(en_tokenizer.word_index) + 1, output_dim=embedding_dim)(decoder_inputs)\n",
        "    decoder_embedding = Dropout(dropout_rate)(decoder_embedding)\n",
        "\n",
        "    hidden_units_decoder = hidden_units * 2 if bidirectional else hidden_units\n",
        "    if cell_type == 'lstm':\n",
        "        decoder_rnn = LSTM(hidden_units_decoder, return_sequences=True, return_state=True)\n",
        "        decoder_outputs, _, _ = decoder_rnn(decoder_embedding, initial_state=encoder_states)\n",
        "    else:  # GRU\n",
        "        decoder_rnn = GRU(hidden_units_decoder, return_sequences=True, return_state=True)\n",
        "        decoder_outputs, _ = decoder_rnn(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "    decoder_outputs = Dropout(dropout_rate)(decoder_outputs)\n",
        "    decoder_dense = Dense(len(en_tokenizer.word_index) + 1, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = optimizer\n",
        "\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "2NozWBZlCKjF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. **Training the Model**\n",
        "def train_model(model, de_train, en_train_shifted, en_train, de_val, en_val_shifted, en_val):\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"model_checkpoint.weights.h5\", monitor='val_loss', save_best_only=True, save_weights_only=True),\n",
        "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        [de_train, en_train_shifted],\n",
        "        np.expand_dims(en_train, -1),\n",
        "        validation_data=([de_val, en_val_shifted], np.expand_dims(en_val, -1)),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=1,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "HrixftZzCMn5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification_metrics(model, de_val, en_val_shifted, en_val):\n",
        "    # Make predictions\n",
        "    predictions = model.predict([de_val, en_val_shifted], batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Flatten y_true and y_pred for evaluation\n",
        "    y_true = en_val.flatten()  # True labels\n",
        "    y_pred = np.argmax(predictions.reshape(-1, predictions.shape[-1]), axis=1)  # Predicted labels\n",
        "\n",
        "    # Check if the length of predictions and true labels match\n",
        "    print(f\"Predictions shape: {y_pred.shape}, True labels shape: {y_true.shape}\")\n",
        "\n",
        "    # Remove padding (0) from both true labels and predictions (Assumes padding is 0)\n",
        "    mask = y_true > 0  # Masking the padding\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    # Print the shapes of y_true and y_pred after masking\n",
        "    print(f\"Shape of y_true after masking: {y_true.shape}\")\n",
        "    print(f\"Shape of y_pred after masking: {y_pred.shape}\")\n",
        "\n",
        "    # Check for length mismatch after masking\n",
        "    if len(y_true) != len(y_pred):\n",
        "        print(f\"Warning: Mismatch in length of true labels and predicted labels. y_true: {len(y_true)}, y_pred: {len(y_pred)}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # ROC AUC - Ensure that predictions are reshaped properly\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, predictions.reshape(-1, predictions.shape[-1]), multi_class='ovr', average='weighted')\n",
        "    except ValueError:\n",
        "        auc = 0.0  # Handle case where AUC cannot be computed\n",
        "\n",
        "    # Calculate ROC curve values for visualization\n",
        "    fpr, tpr, _ = roc_curve(y_true, predictions.reshape(-1, predictions.shape[-1]), pos_label=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "GGk4D2OUCOKS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(accuracy, precision, recall, f1, auc, fpr, tpr):\n",
        "    # Plot Evaluation Metrics\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "    values = [accuracy, precision, recall, f1, auc]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=metrics, y=values)\n",
        "    plt.title(\"Evaluation Metrics\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='blue', label=\"ROC curve (area = %0.2f)\" % auc)\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC)')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iIyUM2tLCP7l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. **Hyperparameter Tuning**\n",
        "def run_hyperparameter_tuning(de_train, en_train_shifted, en_train, de_val, en_val_shifted, en_val):\n",
        "    hypermodel = NMTHyperModel()\n",
        "\n",
        "    tuner = kt.RandomSearch(\n",
        "        hypermodel,\n",
        "        objective='val_loss',\n",
        "        max_trials=5,  # Try a smaller number of trials for testing\n",
        "        directory='nmt_tuning',\n",
        "        project_name='de_en_translation'\n",
        "    )\n",
        "\n",
        "    tuner.search(\n",
        "        [de_train, en_train_shifted],\n",
        "        np.expand_dims(en_train, -1),\n",
        "        validation_data=([de_val, en_val_shifted], np.expand_dims(en_val, -1)),\n",
        "        epochs=5\n",
        "    )\n",
        "\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    best_model = build_model(\n",
        "        embedding_dim=best_hps.get('embedding_dim'),\n",
        "        hidden_units=best_hps.get('hidden_units'),\n",
        "        dropout_rate=best_hps.get('dropout_rate'),\n",
        "        cell_type=best_hps.get('cell_type'),\n",
        "        bidirectional=best_hps.get('bidirectional'),\n",
        "        learning_rate=best_hps.get('learning_rate')\n",
        "    )\n",
        "\n",
        "    return best_model, best_hps"
      ],
      "metadata": {
        "id": "D6xy7Ld1CRWo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct the unpacking of values to match the 9 returned values\n",
        "de_train, en_train, de_tokenizer, en_tokenizer, en_train_shifted, de_val, en_val, en_val_shifted, train_dataset, val_dataset = load_and_preprocess_data()\n",
        "print(\"Data preprocessing completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZEZJpaxCTHo",
        "outputId": "6ca5fc09-96db-40ac-b7ab-e27e862f44fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memuat dataset...\n",
            "Data preprocessing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n"
      ],
      "metadata": {
        "id": "yBPRgANJCUrS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(model, de_train, en_train_shifted, en_train, de_val, en_val_shifted, en_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05wrXqulDMWA",
        "outputId": "4f20f164-05cb-4c56-8d57-14670e769d94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3523/3523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1248s\u001b[0m 353ms/step - accuracy: 0.5682 - loss: 3.1027 - val_accuracy: 0.7192 - val_loss: 2.0719 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification_metrics(model, de_val, en_val_shifted, en_val):\n",
        "    # Make predictions\n",
        "    predictions = model.predict([de_val, en_val_shifted], batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Flatten y_true and y_pred for evaluation\n",
        "    y_true = en_val.flatten()  # True labels\n",
        "    y_pred = np.argmax(predictions.reshape(-1, predictions.shape[-1]), axis=1)  # Predicted labels\n",
        "\n",
        "    # Remove padding (0) from both true labels and predictions (Assumes padding is 0)\n",
        "    mask = y_true > 0  # Masking the padding (only keep valid tokens)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, predictions.reshape(-1, predictions.shape[-1]), multi_class='ovr', average='weighted')\n",
        "    except ValueError:\n",
        "        auc = 0.0  # Handle case where AUC cannot be computed\n",
        "\n",
        "    # Print only the metrics\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1, auc\n"
      ],
      "metadata": {
        "id": "lONrdb1NRrWn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to calculate and print metrics\n",
        "def evaluate_classification_metrics(model, de_val, en_val_shifted, en_val):\n",
        "    # Make predictions\n",
        "    predictions = model.predict([de_val, en_val_shifted], batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Flatten y_true and y_pred for evaluation\n",
        "    y_true = en_val.flatten()  # True labels\n",
        "    y_pred = np.argmax(predictions.reshape(-1, predictions.shape[-1]), axis=1)  # Predicted labels\n",
        "\n",
        "    # Remove padding (0) from both true labels and predictions (Assumes padding is 0)\n",
        "    mask = y_true > 0  # Masking the padding (only keep valid tokens)\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Calculate recall\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # ROC AUC - Ensure that predictions are reshaped properly\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, predictions.reshape(-1, predictions.shape[-1]), multi_class='ovr', average='weighted')\n",
        "    except ValueError:\n",
        "        auc = 0.0  # Handle case where AUC cannot be computed\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "    # Return all metrics\n",
        "    return accuracy, precision, recall, f1, auc\n"
      ],
      "metadata": {
        "id": "Ok-29vc0DOMd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now call the function and unpack all 5 returned values\n",
        "accuracy, precision, recall, f1, auc = evaluate_classification_metrics(model, de_val, en_val_shifted, en_val)\n"
      ],
      "metadata": {
        "id": "dGGYXhJhJU70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a985b10a-b8b7-4ee3-caa9-9597043b5163"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 572ms/step\n",
            "Accuracy: 0.2042\n",
            "Precision: 0.1274\n",
            "Recall: 0.2042\n",
            "F1 Score: 0.1364\n",
            "AUC: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cara Kerja Kode\n",
        "\n",
        "Berikut adalah penjelasan tentang bagaimana kode ini bekerja, termasuk dataset yang digunakan dan proses-proses penting di dalamnya:\n",
        "\n",
        "## 1. Dataset\n",
        "\n",
        "* **Dataset yang digunakan**: Dataset **WMT14 (German-English)** dari HuggingFace, yang digunakan untuk tugas **machine translation** (penerjemahan bahasa) dari bahasa Jerman (German) ke bahasa Inggris (English). Dataset ini berisi pasangan kalimat dalam dua bahasa tersebut.\n",
        "* Dataset ini dibagi menjadi dua bagian utama: **train** dan **validation**. Kita menggunakan **5% data** dari kedua bagian ini untuk pelatihan dan validasi.\n",
        "\n",
        "## 2. Data Preprocessing\n",
        "\n",
        "* **Tokenisasi dan Padding**: Pada tahap ini, kalimat dalam bahasa Jerman (de) dan bahasa Inggris (en) diproses dengan **tokenisasi** menggunakan `Tokenizer` dari Keras, yang mengubah kalimat menjadi urutan angka berdasarkan kata yang ada.\n",
        "* **Padding**: Tokenisasi mengubah kalimat menjadi urutan angka, tetapi panjang kalimat dapat bervariasi. Untuk menyamakan panjangnya, **padding** diterapkan agar setiap urutan memiliki panjang yang konsisten.\n",
        "* **Generator Decoder Input**: Pada model seq2seq (sequence-to-sequence), perlu ada input khusus untuk decoder, yang disiapkan dengan **menggeser** urutan target (dalam hal ini kalimat dalam bahasa Inggris) sehingga model dapat memprediksi kata berikutnya dalam kalimat target.\n",
        "\n",
        "## 3. Model Building (Seq2Seq Model)\n",
        "\n",
        "* **Encoder-Decoder Architecture**: Model ini menggunakan arsitektur **Encoder-Decoder** yang terdiri dari dua bagian:\n",
        "   * **Encoder**: Mengambil urutan input (kalimat dalam bahasa Jerman) dan mengubahnya menjadi representasi vektor yang mengandung informasi penting.\n",
        "   * **Decoder**: Menggunakan representasi vektor dari encoder untuk menghasilkan urutan output (kalimat dalam bahasa Inggris).\n",
        "* **Bidirectional LSTM**: LSTM (Long Short-Term Memory) digunakan untuk memproses urutan data, dan model ini menggunakan **Bidirectional LSTM** yang memungkinkan pemodelan informasi dari kedua arah (kiri ke kanan dan kanan ke kiri).\n",
        "\n",
        "## 4. Training\n",
        "\n",
        "* **Training** dilakukan dengan menggunakan **data pelatihan (train data)** yang telah diproses sebelumnya dan **data validasi (validation data)** untuk memantau performa selama pelatihan.\n",
        "* **Early Stopping** dan **Model Checkpoint** digunakan untuk menghindari overfitting dan menyimpan model terbaik selama pelatihan.\n",
        "\n",
        "## 5. Evaluation\n",
        "\n",
        "Setelah model dilatih, **metrik evaluasi** dihitung menggunakan data validasi:\n",
        "* **Accuracy**: Mengukur berapa banyak prediksi yang benar dibandingkan dengan total prediksi.\n",
        "* **Precision**: Mengukur ketepatan prediksi positif (berkaitan dengan berapa banyak prediksi positif yang benar).\n",
        "\n",
        "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "* **Recall**: Mengukur sejauh mana model dapat menangkap semua contoh positif.\n",
        "\n",
        "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "\n",
        "* **F1-Score**: Rata-rata harmonis dari Precision dan Recall, digunakan untuk menilai performa model secara keseluruhan.\n",
        "\n",
        "$$\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "* **AUC (Area Under the Curve)**: Ukuran kinerja model klasifikasi. AUC yang lebih tinggi menunjukkan bahwa model lebih baik dalam membedakan antara kelas positif dan negatif.\n",
        "\n",
        "## 6. Output Evaluasi\n",
        "\n",
        "Hasil dari metrik-metrik tersebut adalah sebagai berikut:\n",
        "* **Accuracy**: 0.2042\n",
        "* **Precision**: 0.1274\n",
        "* **Recall**: 0.2042\n",
        "* **F1 Score**: 0.1364\n",
        "* **AUC**: 0.0000\n",
        "\n",
        "## Kesimpulan\n",
        "\n",
        "* **Model yang digunakan saat ini menunjukkan hasil evaluasi yang sangat rendah**:\n",
        "   * **Accuracy**: 20.42% – Model hanya benar dalam 1 dari 5 prediksi.\n",
        "   * **Precision**: 12.74% – Model sering memprediksi positif secara keliru.\n",
        "   * **Recall**: 20.42% – Model gagal menangkap sebagian besar prediksi positif yang benar.\n",
        "   * **F1 Score**: 13.64% – Rata-rata harmonis antara precision dan recall yang rendah.\n",
        "   * **AUC**: 0.0000 – Model tidak dapat membedakan antara kelas positif dan negatif."
      ],
      "metadata": {
        "id": "QhIIAeitUiX6"
      }
    }
  ]
}